#!/usr/bin/env python
# -*- coding: latin-1 -*-
#
#   Copyright 2016 Blaise Frederick
#
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.
#
#
# $Author: frederic $
#       $Date: 2016/07/11 14:50:43 $
#       $Id: showxcorr,v 1.41 2016/07/11 14:50:43 frederic Exp $
#
from __future__ import print_function, division

import warnings
import sys
import os
import platform

import matplotlib
import numpy as np
import scipy as sp

import getopt
import rapidtide.miscmath as tide_math
import rapidtide.stats as tide_stats
import rapidtide.io as tide_io
import rapidtide.filter as tide_filt
import rapidtide.fit as tide_fit
import rapidtide.correlate as tide_corr
import rapidtide.nullcorrpass as tide_nullcorr

from scipy.signal import correlate
from scipy.stats.stats import pearsonr
from scipy import sin, arange, pi, randn
from numpy import r_, argmax, zeros, shape, reshape, eye, sqrt
from numpy.random import shuffle, permutation

from matplotlib.pyplot import plot, legend, show, figure


def getNullDistributionData(indata, xcorr_x, thefilter, prewindow, detrendorder, searchstart, searchend,
                            windowfunc='hamming', corrweighting='none', numreps=1000):
    print('estimating significance distribution using ', numreps, ' repetitions')
    corrlist = zeros(numreps, dtype='float')
    corrlist_pear = zeros(numreps, dtype='float')
    xcorr_x_trim = xcorr_x[searchstart:searchend + 1]

    filteredindata = tide_math.corrnormalize(thefilter.apply(Fs, indata),
                                             prewindow=prewindow,
                                             detrendorder=detrendorder,
                                             windowfunc=windowfunc)
    for i in range(0, numreps):
        # make a shuffled copy of the regressors
        shuffleddata = permutation(indata)

        # filter it
        filteredshuffleddata = np.nan_to_num(
            tide_math.corrnormalize(thefilter.apply(Fs, shuffleddata),
                                    prewindow=prewindow,
                                    detrendorder=detrendorder,
                                    windowfunc=windowfunc))

        # crosscorrelate with original
        theshuffledxcorr = tide_corr.fastcorrelate(filteredindata, filteredshuffleddata, usefft=dofftcorr,
                                                   weighting=corrweighting)

        # find and tabulate correlation coefficient at optimal lag
        theshuffledxcorr_trim = theshuffledxcorr[searchstart:searchend + 1]
        maxdelay = xcorr_x_trim[argmax(theshuffledxcorr_trim)]
        corrlist[i] = theshuffledxcorr_trim[argmax(theshuffledxcorr_trim)]

        # find and tabulate correlation coefficient at 0 lag
        corrlist_pear[i] = pearsonr(filteredindata, filteredshuffleddata)[0]

        # progress
        # tide_util.progressbar(i + 1, numreps, label='Percent complete')

    # jump to line after progress bar
    print()

    # return the distribution data
    return corrlist, corrlist_pear


def printthresholds(pcts, thepercentiles, labeltext):
    print(labeltext)
    for i in range(0, len(pcts)):
        print('\tp <', "{:.3f}".format(1.0 - thepercentiles[i]), ': ', pcts[i])


def usage(inputargs):
    print(os.path.basename(inputargs[0]), "- calculate and display crosscorrelation between two timeseries")
    print("")
    print("usage: ", os.path.basename(inputargs[0]), " timecourse1[:COLNUM] timecourse2[:COLNUM] samplerate")
    print(' '.join([
        "[-l LABEL]",
        "[-s STARTTIME]",
        "[-D DURATION]",
        "[-d]",
        "[-F LOWERFREQ,UPPERFREQ[,LOWERSTOP,UPPERSTOP]]",
        "[-V]",
        "[-L]",
        "[-R]",
        "[-C]",
        "[--nodetrend]",
        "[--nowindow]",
        "[-f]",
        "[-o OUTPUTFILE]",
        "[--phat]",
        "[--liang]",
        "[--eckart]",
        "[--savecorr=FILE]",
        "[-z FILENAME]",
        "[-N TRIALS]"]))
    print("")
    print("required arguments:")
    print("    timcoursefile1[:COLNUM]: text file containing a timeseries.  Select column COLNUM if multicolumn file")
    print("    timcoursefile2[:COLNUM]: text file containing a timeseries.  Select column COLNUM if multicolumn file")
    print("    samplerate:              sample rate of the timecourses, in Hz")
    print("")
    print("optional arguments:")
    print("    --nodetrend        - do not detrend the data before correlation")
    print("    --nowindow         - do not prewindow data before corrlation")
    print("    --windowfunc=FUNC  - window function to apply before corrlation (default is Hamming)")
    print("    --cepstral         - check time delay using Choudhary's cepstral technique ")
    print("    --phat             - perform phase alignment transform (PHAT) rather than ")
    print("                         standard crosscorrelation")
    print("    --liang            - perform phase alignment transform with Liang weighting function rather than ")
    print("                         standard crosscorrelation")
    print("    --eckart           - perform phase alignment transform with Eckart weighting function rather than ")
    print("                         standard crosscorrelation")
    print("    -l LABEL           - label for the delay value")
    print("    -s STARTTIME       - time of first datapoint to use in seconds in the first file")
    print("    -D DURATION        - amount of data to use in seconds")
    print("    -r RANGE           - restrict peak search range to +/- RANGE seconds (default is ")
    print("                         +/-15)")
    print("    -d                 - turns off display of graph")
    print("    -F                 - filter data and regressors from LOWERFREQ to UPPERFREQ.")
    print("                         LOWERSTOP and UPPERSTOP can be specified, or will be ")
    print("                         calculated automatically")
    print("    -V                 - filter data and regressors to VLF band")
    print("    -L                 - filter data and regressors to LFO band")
    print("    -R                 - filter data and regressors to respiratory band")
    print("    -C                 - filter data and regressors to cardiac band")
    print("    -T                 - trim data to match")
    print("    -A                 - print data on a single summary line")
    print("    -a                 - if summary mode is on, add a header line showing what values ")
    print("                         mean")
    print("    -f                 - negate (flip) second regressor")
    print("    -savecorr=FILE     - Save the correlation function to the file FILE in xy format")
    print("    -z FILENAME        - use the columns of FILENAME as controlling variables and ")
    print("                         return the partial correlation")
    print("    -N TRIALS          - estimate significance thresholds by Monte Carlo with TRIALS ")
    print("                         repetition")
    print("    -o OUTPUTFILE      - Writes summary lines to OUTPUTFILE (sets -A)")
    print("")
    return ()


def showxcorrx_main(inputargs):

    # get the command line parameters
    searchrange = 15.0
    uselabel = False
    display = True
    corrweighting = 'none'
    prewindow = True
    windowfunc = 'hamming'
    detrendorder = 1
    dopartial = False
    duration = 1000000.0
    starttime = 0.0
    doplot = False
    thelabel = ""
    trimdata = False
    verbose = False
    summarymode = False
    outputfile = None
    dofftcorr = True
    labelline = False
    estimate_significance = False
    writecorrlists = False
    flipregressor = False
    savecorrelation = False
    calccepstraldelay = False
    debug = False
    numreps = 0

    nargs = len(inputargs)
    if nargs < 4:
        usage()
        exit()
    infilename1 = inputargs[1]
    infilename2 = inputargs[2]
    Fs = float(inputargs[3])

    theprefilter = tide_filt.noncausalfilter()

    infilename1, colspec1 = tide_io.parsefilespec(infilename1)
    infilename2, colspec2 = tide_io.parsefilespec(infilename2)

    inputdata1 = np.transpose(tide_io.readvecs(infilename1, colspec=colspec1))
    if np.shape(inputdata1)[1] > 1:
        print('specify only one column for input file 1')
        sys.exit()
    else:
        inputdata1 = inputdata1[:, 0]
    inputdata2 = np.transpose(tide_io.readvecs(infilename2, colspec=colspec2))
    if np.shape(inputdata2)[1] > 1:
        print('specify only one column for input file 2')
        sys.exit()
    else:
        inputdata2 = inputdata2[:, 0]
    numpoints = len(inputdata1)

    # now scan for optional arguments
    try:
        opts, args = getopt.getopt(inputargs[4:], "o:fN:r:z:aATtVLRCF:dl:s:D:w",
                                   ["phat",
                                    "liang",
                                    "eckart",
                                    "nodetrend",
                                    "nowindow",
                                    "windowfunc=",
                                    "cepstral",
                                    "savecorr=",
                                    "debug",
                                    "help"])
    except getopt.GetoptError as err:
        # print help information and exit:
        print(str(err))  # will print something like "option -x not recognized"
        usage()
        sys.exit(2)

    for o, a in opts:
        if o == "-d":
            display = False
            if verbose:
                print('disable display')
        elif o == "-T":
            trimdata = True
            if verbose:
                print('trimming data to match')
        elif o == "--cepstral":
            calccepstraldelay = True
            if verbose:
                print('doing cepstral delay time check')
        elif o == "--liang":
            corrweighting = 'Liang'
            if verbose:
                print('doing Liang weighted correlation')
        elif o == "--eckart":
            corrweighting = 'Eckart'
            if verbose:
                print('doing Eckart weighted correlation')
        elif o == "--phat":
            corrweighting = 'PHAT'
            if verbose:
                print('doing phase alignment transform')
        elif o == "--debug":
            debug = True
            if verbose:
                print('turning on debugging')
        elif o == "-f":
            flipregressor = True
            if verbose:
                print('negating second regressor')
        elif o == "-a":
            labelline = True
            if verbose:
                print('turning on label line')
        elif o == "-t":
            print("DEPRECATION WARNING: detrending is now on by default.  Use --nodetrend to disable it")
        elif o == "--nodetrend":
            detrendorder = 0
            if verbose:
                print('disabling detrending')
        elif o == "-w":
            print("DEPRECATION WARNING: windowing is now on by default.  Use --nowindow to disable it")
        elif o == "--savecorr":
            savecorrelation = True
            corroutputfile = a
            if verbose:
                print('saving correlation function to', corroutputfile)
        elif o == "--nowindow":
            prewindow = False
            if verbose:
                print('disabling prewindowing')
        elif o == "--windowfunc":
            windowfunc = a
            if (windowfunc != 'hamming') and (windowfunc != 'blackmanharris') and (windowfunc != 'hann') and (
                    windowfunc != 'None'):
                print('illegal window function')
                sys.exit()
            if verbose:
                print('using window function:', windowfunc)
        elif o == "-z":
            controlvariablefile = a
            dopartial = True
            if verbose:
                print('performing partial correlations')
        elif o == "-l":
            thelabel = a
            uselabel = True
            if verbose:
                print('label set to', thelabel)
        elif o == "-N":
            numreps = int(a)
            estimate_significance = True
            if verbose:
                print('estimating significance threshold with ', numreps, ' trials')
        elif o == "-r":
            searchrange = float(a)
            if verbose:
                print('peak search restricted to +/-', searchrange, ' seconds')
        elif o == "-D":
            duration = float(a)
            if verbose:
                print('duration set to', duration)
        elif o == "-s":
            starttime = float(a)
            if verbose:
                print('starttime set to', starttime)
        elif o == "-V":
            theprefilter.settype('vlf')
            if verbose:
                print('prefiltering to vlf band')
        elif o == "-L":
            theprefilter.settype('lfo')
            if verbose:
                print('prefiltering to lfo band')
        elif o == "-R":
            theprefilter.settype('resp')
            if verbose:
                print('prefiltering to respiratory band')
        elif o == "-C":
            theprefilter.settype('cardiac')
            if verbose:
                print('prefiltering to cardiac band')
        elif o == "-o":
            verbose = False
            outputfile = a
            summarymode = True
        elif o == "-A":
            verbose = False
            summarymode = True
        elif o == "-F":
            arbvec = a.split(',')
            if len(arbvec) != 2 and len(arbvec) != 4:
                usage()
                sys.exit()
            if len(arbvec) == 2:
                arb_lower = float(arbvec[0])
                arb_upper = float(arbvec[1])
                arb_lowerstop = 0.9 * float(arbvec[0])
                arb_upperstop = 1.1 * float(arbvec[1])
            if len(arbvec) == 4:
                arb_lower = float(arbvec[0])
                arb_upper = float(arbvec[1])
                arb_lowerstop = float(arbvec[2])
                arb_upperstop = float(arbvec[3])
            theprefilter.settype('arb')
            theprefilter.setarb(arb_lowerstop, arb_lower, arb_upper, arb_upperstop)
            if verbose:
                print('prefiltering to ', arb_lower, arb_upper, "(stops at ", arb_lowerstop, arb_upperstop, ")")
        else:
            assert False, "unhandled option"

    if debug:
        dumpfiltered = True
    else:
        dumpfiltered = False
    showpearson = True

    startpoint1 = max([int(starttime * Fs), 0])
    if debug:
        print('startpoint set to ', startpoint1)
    endpoint1 = min([startpoint1 + int(duration * Fs), int(len(inputdata1))])
    if debug:
        print('endpoint set to ', endpoint1)
    endpoint2 = min([int(duration * Fs), int(len(inputdata1)), int(len(inputdata2))])
    trimdata1 = inputdata1[startpoint1:endpoint1]
    trimdata2 = inputdata2[0:endpoint2]

    if trimdata:
        minlen = np.min([len(trimdata1), len(trimdata2)])
        trimdata1 = trimdata1[0:minlen]
        trimdata2 = trimdata2[0:minlen]

    # band limit the regressor if that is needed
    if theprefilter.gettype() != 'none':
        if verbose:
            print("filtering to ", theprefilter.gettype(), " band")
    filtereddata1 = tide_math.corrnormalize(theprefilter.apply(Fs, trimdata1),
                                            prewindow=prewindow,
                                            detrendorder=detrendorder,
                                            windowfunc=windowfunc)
    filtereddata2 = tide_math.corrnormalize(theprefilter.apply(Fs, trimdata2),
                                            prewindow=prewindow,
                                            detrendorder=detrendorder,
                                            windowfunc=windowfunc)
    if flipregressor:
        filtereddata2 *= -1.0
    if dumpfiltered:
        tide_io.writenpvecs(filtereddata1, "filtereddata1.txt")
        tide_io.writenpvecs(filtereddata2, "filtereddata2.txt")

    if dopartial:
        controlvars = tide_io.readnpvecs(controlvariablefile)
        regressorvec = []
        for j in range(0, numregressors):
            regressorvec.append(tide_math.corrnormalize(theprefilter.apply(Fs, controlvars[j, :]),
                                                        prewindow=prewindow,
                                                        detrendorder=detrendorder,
                                                        windowfunc=windowfunc))
        if (np.max(filtereddata1) - np.min(filtereddata1)) > 0.0:
            thefit, filtereddata1 = tide_fit.mlregress(regressorvec, filtereddata1)
        if (np.max(filtereddata2) - np.min(filtereddata2)) > 0.0:
            thefit, filtereddata2 = tide_fit.mlregress(regressorvec, filtereddata2)

    thexcorr = tide_corr.fastcorrelate(filtereddata1, filtereddata2, usefft=dofftcorr, weighting=corrweighting,
                                       displayplots=debug)
    if calccepstraldelay:
        cepdelay = tide_corr.cepstraldelay(filtereddata1, filtereddata2, 1.0 / Fs, displayplots=display)
        cepcoff = tide_corr.delayedcorr(filtereddata1, filtereddata2, cepdelay, 1.0 / Fs)
        print('cepstral delay time is', cepdelay, ', correlation is', cepcoff)
    thepxcorr = pearsonr(filtereddata1, filtereddata2)

    # calculate the coherence
    f, Cxy = sp.signal.coherence(
        tide_math.corrnormalize(theprefilter.apply(Fs, trimdata1),
                                prewindow=prewindow,
                                detrendorder=detrendorder,
                                windowfunc=windowfunc),
        tide_math.corrnormalize(theprefilter.apply(Fs, trimdata2),
                                prewindow=prewindow,
                                detrendorder=detrendorder,
                                windowfunc=windowfunc),
        Fs)

    # calculate the cross spectral density
    f, Pxy = sp.signal.csd(
        tide_math.corrnormalize(theprefilter.apply(Fs, trimdata1),
                                prewindow=prewindow,
                                detrendorder=detrendorder,
                                windowfunc=windowfunc),
        tide_math.corrnormalize(theprefilter.apply(Fs, trimdata2),
                                prewindow=prewindow,
                                detrendorder=detrendorder,
                                windowfunc=windowfunc),
        Fs)

    xcorrlen = len(thexcorr)
    sampletime = 1.0 / Fs
    xcorr_x = r_[0.0:xcorrlen] * sampletime - (xcorrlen * sampletime) / 2.0 + sampletime / 2.0
    halfwindow = int(searchrange * Fs)
    corrzero = xcorrlen // 2
    searchstart = corrzero - halfwindow
    searchend = corrzero + halfwindow
    xcorr_x_trim = xcorr_x[searchstart:searchend + 1]
    thexcorr_trim = thexcorr[searchstart:searchend + 1]
    if debug:
        print('searching for peak correlation over range ', searchstart, searchend)
    maxdelay = xcorr_x_trim[argmax(thexcorr_trim)]
    if debug:
        print('maxdelay before refinement', maxdelay)
    dofindmaxlag = True
    if dofindmaxlag:
        maxindex, maxdelay, maxval, maxsigma, maskval, failreason, peakstart, peakend = tide_fit.findmaxlag_gauss(
            xcorr_x_trim, thexcorr_trim, -searchrange, searchrange, 1000.0,
            refine=True,
            useguess=False,
            fastgauss=False,
            displayplots=False)
        if debug:
            print(maxindex, maxdelay, maxval, maxsigma, maskval, failreason)
        R = maxval
    if debug:
        print('maxdelay after refinement', maxdelay)
        if failreason > 0:
            print('failreason =', failreason)
    else:
        R = thexcorr_trim[argmax(thexcorr_trim)]

    # set the significance threshold
    if estimate_significance:
        # generate a list of correlations from shuffled data
        '''corrlist, corrlist_pear = getNullDistributionData(trimdata1, xcorr_x, theprefilter,
                                                          prewindow, detrendorder, searchstart, searchend,
                                                          corrweighting=corrweighting, numreps=numreps,
                                                          windowfunc=windowfunc)'''
        optiondict = {
            'numestreps':        numreps,
            'showprogressbar':   False,
            'usewindowfunc':     windowfunc,
            'detrendorder':      detrendorder,
            'windowfunc':        windowfunc,
            'corrweighting':     corrweighting,
            'nprocs':            1,
            'widthlimit':        1000.0,
            'bipolar':           False,
            'fixdelay':          False,
            'findmaxtype':       'gauss',
            'lagmin':            -searchrange,
            'lagmax':            searchrange,
            'absmaxsigma':       1000.0,
            'edgebufferfrac':    0.0,
            'lthreshval':        0.0,
            'uthreshval':        1.0,
            'debug':             debug,
            'gaussrefine':       True,
            'fastgauss':         False,
            'enforcethresh':     True,
            'lagmod':            1000.0,
            'searchfrac':        0.5,
            'permutationmethod': 'shuffle',
            'hardlimit':         True
        }

        if debug:
            print(optiondict)

        corrlist = tide_nullcorr.getNullDistributionDatax(trimdata1,
                                                          xcorr_x,
                                                          theprefilter,
                                                          Fs,
                                                          corrzero,
                                                          searchstart,
                                                          searchend,
                                                          optiondict)

        # calculate percentiles for the crosscorrelation from the distribution data
        histlen = 100
        thepercentiles = [0.95, 0.99, 0.995]

        pcts, pcts_fit, histfit = tide_stats.sigFromDistributionData(corrlist, histlen, thepercentiles)
        if debug:
            tide_stats.printthresholds(pcts, thepercentiles, 'Crosscorrelation significance thresholds from data:')
            tide_stats.printthresholds(pcts_fit, thepercentiles, 'Crosscorrelation significance thresholds from fit:')

        # calculate significance for the pearson correlation
        pearpcts, pearpcts_fit, histfit = tide_stats.sigFromDistributionData(corrlist_pear, histlen, thepercentiles)
        if debug:
            tide_stats.printthresholds(pearpcts, thepercentiles, 'Pearson correlation significance thresholds from data:')
            tide_stats.printthresholds(pearpcts_fit, thepercentiles,
                                       'Pearson correlation significance thresholds from fit:')

        if writecorrlists:
            tide_io.writenpvecs(corrlist, "corrlist.txt")
            tide_io.writenpvecs(corrlist_pear, "corrlist_pear.txt")


    if debug:
        print(thepxcorr)

    if summarymode:
        if estimate_significance:
            thelabelitems = ['pearson_R',       'pearson_R(p=0.05)',  'xcorr_R', 'xcorr_R(p=0.05)', 'xcorr_maxdelay']
            thedataitems =  [ str(thepxcorr[0]), str(pearpcts_fit[0]), str(R),    str(pcts_fit[0]),  str(-maxdelay)]
        else:
            thelabelitems = ['pearson_R',       'pearson_p',       'xcorr_R', 'xcorr_maxdelay']
            thedataitems =  [ str(thepxcorr[0]), str(thepxcorr[1]), str(R),    str(-maxdelay)]
        if uselabel:
            thelabelitems = ['thelabel'] + thelabelitems
            thedataitems =  [thelabel] + thedataitems
        if labelline:
            outputstring = '\t'.join(thelabelitems) + '\n' + '\t'.join(thedataitems)
        else:
            outputstring = '\t'.join(thedataitems)
        if outputfile is None:
            print(outputstring)
        else:
            with open(outputfile, "w") as text_file:
                text_file.write(outputstring + '\n')
    else:
        # report the pearson correlation
        if showpearson:
            print('Pearson_R:\t', thepxcorr[0])
            if estimate_significance:
                for idx, percentile in enumerate(thepercentiles):
                    print('    pear_p(', "{:.3f}".format(1.0 - percentile), '):\t', pearpcts[idx])
            print("")
        if uselabel:
            print(thelabel, ":\t", -maxdelay)
        else:
            print("Crosscorrelation_Rmax:\t", R)
            print("Crosscorrelation_maxdelay:\t", -maxdelay)
            if estimate_significance:
                for idx, percentile in enumerate(thepercentiles):
                    print('    xc_p(', "{:.3f}".format(1.0 - percentile), '):\t', pcts[idx])
            print(infilename1, "[0 seconds] == ", infilename2, "[", -maxdelay, " seconds]")

    if display:
        fig = figure()
        ax = fig.add_subplot(111)
        # ax.set_title('GCC')
        plot(xcorr_x, thexcorr, 'k')
        if debug:
            fig = figure()
            plot(f, Cxy)
            fig = figure()
            plot(f, np.sqrt(np.abs(Pxy)) / np.max(np.sqrt(np.abs(Pxy))))
            plot(f, np.angle(Pxy) / (2.0 * pi * f))
        show()

    if savecorrelation:
        tide_io.writenpvecs(np.stack((xcorr_x, thexcorr), axis=0), corroutputfile)


if __name__ == '__main__':

    # grab the command line arguments then pass them off.
    nargs = len(sys.argv)
    if nargs < 4:
        usage(sys.argv)
        exit()

    showxcorrx_main(sys.argv)
